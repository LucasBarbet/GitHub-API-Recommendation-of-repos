# GitHub Star Recommender ğŸŒŸ

Ce projet est un systÃ¨me de recommandation de dÃ©pÃ´ts GitHub basÃ© sur le filtrage collaboratif. Il utilise l'API GitHub pour collecter des donnÃ©es, MongoDB pour le stockage, et une **SVD (Singular Value Decomposition)** implÃ©mentÃ©e via **scikit-learn** pour gÃ©nÃ©rer des prÃ©dictions.

L'objectif est de suggÃ©rer des dÃ©pÃ´ts pertinents Ã  un utilisateur en analysant les similitudes avec les historiques de "stars" d'utilisateurs experts ("Power Users").

## ğŸ“‹ Table des matiÃ¨res

- [Architecture du Projet](#-architecture-du-projet)
- [Logique de Collecte & DonnÃ©es](#-logique-de-collecte--donn%C3%A9es)
- [ModÃ©lisation (SVD)](#-mod%C3%A9lisation-svd)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Utilisation](#-utilisation)

## ğŸ“‚ Architecture du Projet

Le projet suit une structure modulaire standard pour les pipelines de Machine Learning, sÃ©parant la configuration, le code source (src) et les expÃ©rimentations (research).

```text
â”œâ”€â”€ .github/workflows/ # CI/CD pipelines  
â”œâ”€â”€ config/ # Configuration globale (config.yaml)  
â”œâ”€â”€ research/ # Notebooks pour l'analyse exploratoire (trails.ipynb)  
â”œâ”€â”€ src/  
â”‚ â””â”€â”€ githubRecommender/ # Package principal  
â”‚ â”œâ”€â”€ components/ # Modules logiques (Data Ingestion, Transformation, Model Trainer)  
â”‚ â”œâ”€â”€ config/ # Gestionnaires de configuration  
â”‚ â”œâ”€â”€ entity/ # Data Classes et entitÃ©s  
â”‚ â”œâ”€â”€ pipeline/ # Orchestration des Ã©tapes (Train, Predict)  
â”‚ â””â”€â”€ utils/ # Fonctions utilitaires communes  
â”œâ”€â”€ templates/ # Fichiers HTML pour l'interface Web (index.html)  
â”œâ”€â”€ app.py # Application Web (Flask/Streamlit)  
â”œâ”€â”€ main.py # Point d'entrÃ©e pour l'exÃ©cution du pipeline  
â”œâ”€â”€ params.yaml # HyperparamÃ¨tres du modÃ¨le SVD  
â”œâ”€â”€ schema.yaml # SchÃ©ma des donnÃ©es  
â”œâ”€â”€ Dockerfile # Conteneurisation de l'application  
â””â”€â”€ requirements.txt # DÃ©pendances Python
```

## ğŸ” Logique de Collecte & DonnÃ©es

### StratÃ©gie "Power Users"

Pour garantir la pertinence des recommandations et rÃ©duire le bruit dans la matrice, nous appliquons un filtre trÃ¨s strict lors de l'extraction des donnÃ©es (ETL).

Nous ne conservons un utilisateur dans notre base MongoDB que si :

- Il a donnÃ© une "star" Ã  au moins **100 dÃ©pÃ´ts**.
- **Chacun** de ces 100 dÃ©pÃ´ts possÃ¨de au moins **5 000 stars** au total.

**Pourquoi ?** Ce filtre vise Ã  isoler les utilisateurs expÃ©rimentÃ©s qui effectuent une curation de haute qualitÃ© sur des projets technologiques majeurs, permettant Ã  l'algorithme d'apprendre des motifs robustes.

### SchÃ©ma MongoDB
Les donnÃ©es sont stockÃ©es dans une collection (par exemple `users`).
**Structure rÃ©elle d'un document :**

```json
{
  "_id": "vanpelt",               // Identifiant utilisateur (String)
  "date_ajout": "2025-11-17...",  // Date d'extraction
  "repos": [                      // Liste simple de Strings ("owner/repo")
    "obra/superpowers",
    "jdx/mise",
    "dop251/goja",
    "grafana/k6"
    // ... (100 Ã©lÃ©ments filtrÃ©s)
  ]
}
```

## ğŸ§  ModÃ©lisation (SVD)

Le moteur de recommandation repose sur une approche de factorisation matricielle.

\$\$M \\approx U \\Sigma V^T\$\$

Nous utilisons TruncatedSVD de la bibliothÃ¨que **scikit-learn**.

- **Construction de la Matrice :** Transformation des donnÃ©es MongoDB en une "Sparse Matrix" (Utilisateurs \$\\times\$ DÃ©pÃ´ts).
- **RÃ©duction de dimension :** L'algorithme compresse cette matrice pour extraire les caractÃ©ristiques latentes (goÃ»ts cachÃ©s des utilisateurs).
- **PrÃ©diction :** Le produit scalaire des matrices rÃ©duites permet de prÃ©dire le score d'intÃ©rÃªt d'un utilisateur pour un dÃ©pÃ´t non encore visitÃ©.

## ğŸ›  Installation

### PrÃ©requis

- Python 3.8+
- MongoDB (Instance locale ou Atlas)
- Compte GitHub (pour le Token API)

### Ã‰tapes

- Cloner le dÃ©pÃ´t :  
    Bash  
    git clone <https://github.com/LucasBarbet/GitHub-API-Recommendation-of-repos.git>  
    cd GitHub-API-Recommendation-of-repos  

- CrÃ©er un environnement virtuel et installer les dÃ©pendances :  
    Bash  
    python -m venv venv  
    \# Windows  
    venv\\Scripts\\activate  
    \# Linux/Mac  
    source venv/bin/activate  
    <br/>pip install -r requirements.txt  

## âš™ï¸ Configuration

- Variables d'environnement :  
    CrÃ©ez un fichier .env ou exportez vos variables pour la connexion Ã  la base de donnÃ©es et l'API GitHub.  
    Bash  
    export GITHUB_TOKEN="votre_token_ici"  
    export MONGO_URI="mongodb://localhost:27017/"  

- ParamÃ¨tres du modÃ¨le :  
    Modifiez params.yaml pour ajuster les hyperparamÃ¨tres de la SVD (ex: nombre de composants).  
    YAML  
    svd_model:  
    n_components: 50  
    n_iter: 5  
    random_state: 42  

## â–¶ï¸ Utilisation

### 1\. ExÃ©cuter le Pipeline (ETL + EntraÃ®nement)

Pour lancer la collecte des donnÃ©es, le traitement et l'entraÃ®nement du modÃ¨le via le point d'entrÃ©e principal :

Bash

python main.py  

_Cela dÃ©clenchera les pipelines dÃ©finis dans src/.../pipeline/._

### 2\. Lancer l'Application Web

Pour utiliser l'interface graphique et visualiser les recommandations :

Bash

python app.py  

L'application sera accessible sur <http://localhost:5000> (ou le port dÃ©fini).

### 3\. ExpÃ©rimentation

Les notebooks dans le dossier research/ (ex: trails.ipynb) peuvent Ãªtre utilisÃ©s pour tester de nouvelles hypothÃ¨ses ou visualiser la distribution des stars avant de modifier le code de production.
